{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c4cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  가위바위보 프로젝트 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "648aeed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 라이브러리 버전을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c29b438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53201f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 호출\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe59978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113  images to be resized.\n",
      "113  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지를 불러와서 28x28 사이즈로 변경\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e816ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113  images to be resized.\n",
      "113  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지도 28x28로 변경\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68867253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123  images to be resized.\n",
      "123  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지도 28x28로 변경\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bd47436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 356 입니다.\n",
      "x_train shape: (600, 28, 28, 3)\n",
      "y_train shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "# 숫자 손글자 인식기 설정\\\n",
    "# load_data() 함수 만들기  (이미지가 있는 폴더 위치를 받는다.)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=600):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1614ce1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 실제 이미지를 불러온다.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b469b861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 31,050\n",
      "Trainable params: 31,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 가위바위보를 인식하는 딥러닝 네트워크를 설계한다.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()   # 새로운 모델을 만든다.\n",
    "model.add(keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 3)))  # 1. 이미지에서 특징을 감지하는 Convolutional 레이어를 추가한다.\n",
    "model.add(keras.layers.MaxPool2D(2, 2))                                  # 2. 특징 맵을 축소하는 MaxPooling 레이어를 한다.\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))            # 3. 더 복잡한 특징을 감지하는 두 번째 Convolutional 레이어를 한다.\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))                             # 4. 다시 특징 맵을 축소하는 두 번째 MaxPooling 레이어를 추가한다..\n",
    "model.add(keras.layers.Flatten())                                        # 5. 모든 특징을 하나의 일렬로 펼치는 Flatten 레이어를 추가한다.\n",
    "model.add(keras.layers.Dense(32, activation='relu'))                     # 6. 특징을 기반으로한 판단을 하는 Dense 레이어를 추가한다.\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))                  # 7. 최종적인 판단 결과를 출력하는 Dense 레이어를 추가한다. (클래스가 10개이므로 10개의 뉴런)\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))                  # 현재까지 추가된 Layer의 개수를 출력한다.\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa9dc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 1s 20ms/step - loss: 6.4835 - accuracy: 0.5467\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1.5890 - accuracy: 0.7150\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 1.2102 - accuracy: 0.8167\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.8981 - accuracy: 0.8567\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.5322 - accuracy: 0.9033\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.3311 - accuracy: 0.9117\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.1974 - accuracy: 0.9417\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.1662 - accuracy: 0.9483\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.1264 - accuracy: 0.9617\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.1220 - accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbc863ee80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딥러닝 네트워크 학습시킨다.\n",
    "\n",
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30462d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n",
      "0  images to be resized.\n",
      "0  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 4 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_646/4238808476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# x_test, y_test 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_scissor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_rock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_paper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_scissor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_rock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_paper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 4 dimension(s)"
     ]
    }
   ],
   "source": [
    "# 테스트용 데이터인 x_test, y_test를 만든다.\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np  \n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images = glob.glob(img_path + \"/*.jpg\")\n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    target_size = (28, 28)\n",
    "    resized_images = []  \n",
    "\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "\n",
    "                                                   \n",
    "        img_array = np.array(new_img)              # 이미지를 numpy 배열로 변환하여 리스트에 추가 (모든 이미지의 차원을 일치시킨다.\n",
    "        img_array = img_array.reshape(28, 28, 3)   # 이미지의 차원을 (높이, 너비, 채널)로 맞추어준다.\n",
    "        resized_images.append(img_array)\n",
    "\n",
    "    print(len(images), \" images resized.\")\n",
    "    return np.array(resized_images)  # 수정된 부분\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "x_test_scissor = resize_images(image_dir_path)  \n",
    "y_test_scissor = np.zeros(len(x_test_scissor))  \n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "x_test_rock = resize_images(image_dir_path)  \n",
    "y_test_rock = np.ones(len(x_test_rock))  \n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "x_test_paper = resize_images(image_dir_path)  \n",
    "y_test_paper = np.full(len(x_test_paper), 2)  \n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "# x_test, y_test 생성\n",
    "x_test = np.concatenate((x_test_scissor, x_test_rock, x_test_paper), axis=0)\n",
    "y_test = np.concatenate((y_test_scissor, y_test_rock, y_test_paper), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74b38b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 459.2641 - accuracy: 0.6276 - val_loss: 92.8720 - val_accuracy: 0.5521\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 38.8316 - accuracy: 0.6224 - val_loss: 20.4268 - val_accuracy: 0.5833\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 21.0138 - accuracy: 0.6094 - val_loss: 19.3206 - val_accuracy: 0.5104\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 18.9573 - accuracy: 0.5885 - val_loss: 3.1423 - val_accuracy: 0.6562\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 13.1004 - accuracy: 0.6094 - val_loss: 5.0326 - val_accuracy: 0.6042\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.5881 - accuracy: 0.6667 - val_loss: 4.6323 - val_accuracy: 0.6354\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.8469 - accuracy: 0.6641 - val_loss: 9.1797 - val_accuracy: 0.5833\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.6601 - accuracy: 0.7031 - val_loss: 4.5073 - val_accuracy: 0.6250\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.2197 - accuracy: 0.6771 - val_loss: 15.2767 - val_accuracy: 0.5625\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 12.3941 - accuracy: 0.6328 - val_loss: 27.1655 - val_accuracy: 0.5833\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11.3676 - accuracy: 0.6953 - val_loss: 8.2217 - val_accuracy: 0.6458\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.5025 - accuracy: 0.7656 - val_loss: 4.4714 - val_accuracy: 0.7083\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.6676 - accuracy: 0.7917 - val_loss: 3.4444 - val_accuracy: 0.7083\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5539 - accuracy: 0.7708 - val_loss: 4.7959 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.5399 - accuracy: 0.7474 - val_loss: 1.0005 - val_accuracy: 0.8542\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.9885 - accuracy: 0.8021 - val_loss: 1.7285 - val_accuracy: 0.7604\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.2163 - accuracy: 0.8438 - val_loss: 0.9474 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.9343 - accuracy: 0.9089 - val_loss: 0.7950 - val_accuracy: 0.8854\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.3593 - accuracy: 0.8438 - val_loss: 2.1607 - val_accuracy: 0.7812\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.5613 - accuracy: 0.8438 - val_loss: 1.5201 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_646/2246150060.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# 학습된 모델 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Accuracy: {test_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "# 준비한 테스트용 데이토로 위에서 훈련시킨 model을 사용하여 test_accuracy를 측정한다.\n",
    "\n",
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋 로드 및 전처리 (예시로 데이터셋을 x_train, y_train으로 가정)\n",
    "# x_train, y_train은 이미지와 레이블에 해당하는 데이터야 한다.\n",
    "# 이 예시에서는 임의의 데이터를 사용하므로 실제 데이터에 맞게 수정이 필요하다.\n",
    "\n",
    "# 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28, 3)))  # 예시로 입력 차원은 (28, 28, 3)으로 가정\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # 클래스 개수에 맞게 설정 (가위, 바위, 보)\n",
    "\n",
    "# 데이터셋 분리\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 20  # 적절한 에폭 수를 선택한다.\n",
    "batch_size = 32  # 적절한 배치 크기를 선택한다.\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val))\n",
    "\n",
    "# 학습된 모델 평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357fe271",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 프로젝트 회고록\n",
    "\n",
    "A. 배운 점\n",
    "\n",
    "1. 딥러닝 기본 이해:    딥러닝 기초 개념을 실제로 활용하며 깊게 이해할 수 있었습니다.\n",
    "2. 모델 구현 및 학습:   Sequential 모델로 간단한 신경망을 만들고, 이미지 데이터로 모델을 훈련시키는 경험을 쌓았습니다.\n",
    "3. 하이퍼파라미터 조절: 에폭 수, 배치 크기 등 하이퍼파라미터를 조절해가며 모델 성능을 확인할 수 있었습니다.\n",
    "4. 이미지 데이터 처리:  PIL 라이브러리를 사용하여 이미지를 로드하고 전처리하는 방법을 배웠습니다.\n",
    "5. 프로젝트 경험:       모델을 훈련하고 테스트하는 전과정을 경험할 수 있었습니다.\n",
    "\n",
    "B. 어려웠던 점\n",
    "\n",
    "1. 차원 관리: 이미지 데이터의 차원 처리가 처음에 어려웠습니다. \n",
    "              특히, 컬러 이미지의 경우 채널 차원을 올바르게 처리하는 데 시간이 걸렸습니다.\n",
    "2. 하이퍼파라미터 조절: 어떤 하이퍼파라미터가 좋을지 찾는 것이 처음에는 어려웠습니다.\n",
    "\n",
    "C. 개선할 점\n",
    "\n",
    "1. 더 많은 데이터 사용:현재는 100개 정도(초과)의 이미지를 사용했는데, 더 많은 데이터를 활용하면 모델의 성능을 향상시킬 수 있을 것입니다.\n",
    "2. 모델 구조 변경:더 복잡한 모델을 시도하고, 다양한 구조를 실험하여 어떤 것이 가장 적합한지 확인할 필요가 있습니다.\n",
    "\n",
    "D. 느낀 점\n",
    "\n",
    "이번 프로젝트를 통해 딥러닝 모델을 만들고 학습시키는 과정을 경험했습니다. \n",
    "기초 단계에서 많은 것을 익히고 있다는 느낌이 들었고, 특히 하이퍼파라미터 조절과 모델 성능 평가에 대한 고민이 많았습니다. \n",
    "더 많은 경험과 학습을 통해 실력을 향상시켜 나가고 싶습니다. \n",
    "솔직하 아직도 부족하지만 매번 많은 도움을 주신 퍼실분들께 감사드립니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
