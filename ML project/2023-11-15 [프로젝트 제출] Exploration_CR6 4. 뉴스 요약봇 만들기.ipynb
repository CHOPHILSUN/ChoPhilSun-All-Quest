{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cacf604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n",
      "2.6.0\n",
      "1.3.3\n",
      "1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 4-1. 프로젝트: 뉴스기사 요약해보기\n",
    "\n",
    "# 새로운 데이터셋에 대해서 추상적 요약과 추출적 요약을 모두 해보는 시간을 가져봐요.\n",
    "\n",
    "# 먼저 주요 라이브러리 버전을 확인해 보죠.\n",
    "\n",
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "import pandas\n",
    "import pandas as pd  \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# nltk 불용어 다운로드\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(pandas.__version__)\n",
    "print(version('summa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bfa2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. 데이터 수집하기\n",
    "# 데이터는 아래 링크에 있는 뉴스 기사 데이터(news_summary_more.csv)를 사용하세요.\n",
    "\n",
    "# sunnysai12345/News_Summary\n",
    "# 아래의 코드로 데이터를 다운로드할 수 있어요.\n",
    "\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e793fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>Who is Sandeep Bakhshi, the new ICICI Bank COO?</td>\n",
       "      <td>Sandeep Bakhshi, the new Chief Operating Offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>Biggest blunder of my career was to launch Dis...</td>\n",
       "      <td>Bajaj Auto MD Rajiv Bajaj has described the la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68674</th>\n",
       "      <td>18-yr-old shuttler dies at Sports Authority of...</td>\n",
       "      <td>An 18-year-old badminton player collapsed and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4333</th>\n",
       "      <td>Trump vows to cut aid to Central American nati...</td>\n",
       "      <td>US President Donald Trump has vowed to cut aid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83206</th>\n",
       "      <td>Drugs worth over $1bn set on fire in three Asi...</td>\n",
       "      <td>Thailand, Myanmar, and Cambodia have burned ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72726</th>\n",
       "      <td>Bangladesh defeat Australia for the 1st time i...</td>\n",
       "      <td>Bangladesh registered its first ever Test win ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>Bill to end Pak 'Major non-NATO ally' status t...</td>\n",
       "      <td>Republican Congressman Andy Biggs has introduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37869</th>\n",
       "      <td>Should PM react if some dog dies: Muthalik on ...</td>\n",
       "      <td>Speaking about questions on PM Narendra Modi's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26331</th>\n",
       "      <td>Startup that raised $2.3 bn to sell 1st AR hea...</td>\n",
       "      <td>US-based augmented reality (AR) startup Magic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59245</th>\n",
       "      <td>Japanese brand apologises over 'No Chinese' si...</td>\n",
       "      <td>Pola, a Japanese cosmetic brand, has apologise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "37675    Who is Sandeep Bakhshi, the new ICICI Bank COO?   \n",
       "8904   Biggest blunder of my career was to launch Dis...   \n",
       "68674  18-yr-old shuttler dies at Sports Authority of...   \n",
       "4333   Trump vows to cut aid to Central American nati...   \n",
       "83206  Drugs worth over $1bn set on fire in three Asi...   \n",
       "72726  Bangladesh defeat Australia for the 1st time i...   \n",
       "2361   Bill to end Pak 'Major non-NATO ally' status t...   \n",
       "37869  Should PM react if some dog dies: Muthalik on ...   \n",
       "26331  Startup that raised $2.3 bn to sell 1st AR hea...   \n",
       "59245  Japanese brand apologises over 'No Chinese' si...   \n",
       "\n",
       "                                                    text  \n",
       "37675  Sandeep Bakhshi, the new Chief Operating Offic...  \n",
       "8904   Bajaj Auto MD Rajiv Bajaj has described the la...  \n",
       "68674  An 18-year-old badminton player collapsed and ...  \n",
       "4333   US President Donald Trump has vowed to cut aid...  \n",
       "83206  Thailand, Myanmar, and Cambodia have burned ne...  \n",
       "72726  Bangladesh registered its first ever Test win ...  \n",
       "2361   Republican Congressman Andy Biggs has introduc...  \n",
       "37869  Speaking about questions on PM Narendra Modi's...  \n",
       "26331  US-based augmented reality (AR) startup Magic ...  \n",
       "59245  Pola, a Japanese cosmetic brand, has apologise...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebfe660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "\n",
    "# 실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. \n",
    "# 만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea29550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f575bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S<데이터 수집하기>\n",
    "\n",
    "# 데이터는 아래 링크에 있는 뉴스 기사 데이터(news_summary_more.csv)를 사용하세요.\n",
    "\n",
    "# sunnysai12345/News_Summary\n",
    "# 아래의 코드로 데이터를 다운로드할 수 있어요.\n",
    "\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a96439c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54558</th>\n",
       "      <td>Russia slams US' plan to sell anti-missile sys...</td>\n",
       "      <td>Russia on Thursday slammed the US over its pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32105</th>\n",
       "      <td>Japan, N Korea should normalise relations: S K...</td>\n",
       "      <td>Japan and North Korea should begin talks to no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22728</th>\n",
       "      <td>Jet Airways plane tries to take off from taxiw...</td>\n",
       "      <td>Saudi Arabia's Aviation Investigation Bureau h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88602</th>\n",
       "      <td>I would love to play role of goddess Sita onsc...</td>\n",
       "      <td>Alia Bhatt has said she would love to play the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28753</th>\n",
       "      <td>Jio takes $1 billion loan to pay Samsung for e...</td>\n",
       "      <td>Reliance Jio has secured $1-billion worth of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14318</th>\n",
       "      <td>Impossible for me to work with such people: Hr...</td>\n",
       "      <td>Reacting to sexual harassment allegations agai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34143</th>\n",
       "      <td>Man standing on Mumbai platform pushed to deat...</td>\n",
       "      <td>A CCTV footage has revealed that a 56-year-old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79482</th>\n",
       "      <td>William, Kate try to get Game of Thrones spoil...</td>\n",
       "      <td>The Duke and Duchess of Cambridge, Prince Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88600</th>\n",
       "      <td>I will always be the naked girl on a wrecking ...</td>\n",
       "      <td>Miley Cyrus, while talking about her music vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93987</th>\n",
       "      <td>Army was cheated to pay rent for land in PoK: ...</td>\n",
       "      <td>Defence Minister Arun Jaitley on Tuesday said ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "54558  Russia slams US' plan to sell anti-missile sys...   \n",
       "32105  Japan, N Korea should normalise relations: S K...   \n",
       "22728  Jet Airways plane tries to take off from taxiw...   \n",
       "88602  I would love to play role of goddess Sita onsc...   \n",
       "28753  Jio takes $1 billion loan to pay Samsung for e...   \n",
       "14318  Impossible for me to work with such people: Hr...   \n",
       "34143  Man standing on Mumbai platform pushed to deat...   \n",
       "79482  William, Kate try to get Game of Thrones spoil...   \n",
       "88600  I will always be the naked girl on a wrecking ...   \n",
       "93987  Army was cheated to pay rent for land in PoK: ...   \n",
       "\n",
       "                                                    text  \n",
       "54558  Russia on Thursday slammed the US over its pla...  \n",
       "32105  Japan and North Korea should begin talks to no...  \n",
       "22728  Saudi Arabia's Aviation Investigation Bureau h...  \n",
       "88602  Alia Bhatt has said she would love to play the...  \n",
       "28753  Reliance Jio has secured $1-billion worth of t...  \n",
       "14318  Reacting to sexual harassment allegations agai...  \n",
       "34143  A CCTV footage has revealed that a 56-year-old...  \n",
       "79482  The Duke and Duchess of Cambridge, Prince Will...  \n",
       "88600  Miley Cyrus, while talking about her music vid...  \n",
       "93987  Defence Minister Arun Jaitley on Tuesday said ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c530b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "이 데이터는 기사의 본문에 해당되는 text와 headlines 두 가지 열로 구성되어져 있습니다.\n",
    "\n",
    "추상적 요약을 하는 경우에는 text를 본문, headlines를 이미 요약된 데이터로 삼아서 모델을 학습할 수 있어요. \n",
    "추출적 요약을 하는 경우에는 오직 text열만을 사용하세요.\n",
    "\n",
    "Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "\n",
    "실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. \n",
    "만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해 보세요.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922760d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "# 빈칸으로 존재하는 null 데이터, 의미는 같지만 다른 식으로 작성된 글 같은 중복 항목과 같은 학습할 때 방해가 되는 데이터 제거\n",
    "    \n",
    "# 중복 샘플과 NULL 값이 존재하는 샘플 제거\n",
    "# 우선 데이터의 중복 샘플 유무를 확인\n",
    "\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3c8265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "중복을 제외한다면 text에는 98,360 개, headlines에는 98,280개의 유니크한 데이터가 존재한다.\n",
    "사실 이 데이터의 headlines는 아주 간단한 요약들도 많아서 Text가 달라도 headlines는 동일할 수 있다.\n",
    "하지만 Text 자체가 중복이 된 경우는 중복 샘플이므로 제거가 필요하다.\n",
    "\n",
    "데이터프레임의 drop_duplicates()를 사용하면, 손쉽게 중복 샘플을 제거할 수 있다.\n",
    "'''\n",
    "\n",
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꾼다.\n",
    "\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24925da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "중복이 제거되면서 샘플 수가 98,360개로 줄어들었어요. \n",
    "그런데 만약 데이터 Null 값을 가지는 샘플이 있었다면, drop_duplicates()가 중복된 Null들을 지워주기는 하겠지만, \n",
    "여전히 Null 값 한 개가 어딘가 남아있을 수 있어요. 데이터에 Null 값이 남아있는지 볼게요.\n",
    "\n",
    "데이터프레임에 Null 값이 있는지 확인하는 방법은 .isnull().sum()을 사용하면 알아볼 수 있어요.\n",
    "\n",
    "'''\n",
    "\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74561d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 정규화와 불용어 제거\n",
    "\n",
    "'''\n",
    "살아남은 88,425개의 샘플에는 수많은 단어들이 있어요. \n",
    "그런데 사실 그 단어들 중에서는 같은 의미인데도 다른 표현으로 쓰여 마치 다른 단어들처럼 간주되는 경우가 있어요.\n",
    "\n",
    "예를 들어서 it'll은 it will과 같고, mustn't과 must not은 사실 같은 표현이죠. \n",
    "이런 경우 기계가 굳이 이들을 마치 다른 단어로 간주하게 해서 연산량을 늘리는 것보다는 기계 학습 전에 \n",
    "미리 같은 표현으로 통일시켜주는 것이 기계의 연산량을 줄일 수 있는 방법이에요.\n",
    "\n",
    "이러한 방법론을 텍스트 처리에서는 텍스트 정규화(text normalization) 라고 해요.\n",
    "\n",
    "여기서는 텍스트 정규화를 위한 사전(dictionary)을 아래와 같이 구성할 거예요. 이 사전은 아래의 링크에서 참고하여 만들었어요.\n",
    "\n",
    "정규화 사전 출처\n",
    "https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29e0eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fc54526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "이제 정규화 준비까지 마쳤어요.\n",
    "\n",
    "하지만 아직 끝난 게 아니에요. 일반적으로 텍스트에는 자주 등장하지만 자연어 처리를 할 때 \n",
    "실질적으로 별 도움이 되지 않는 단어들이 존재해요. 이를 불용어(stopwords)라고 불러요. 때로는 \n",
    "불용어를 제거하는 것이 자연어 처리의 성능을 높이는 방법일 수 있어요. \n",
    "여기서는 NLTK에서 제공하는 불용어 리스트를 참조해, 샘플에서 불용어를 제거할 거예요.\n",
    "\n",
    "'''\n",
    "\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa3f1149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "NLTK에서 미리 정의하여 제공하고 있는 불용어는 총 179개라는 것을 볼 수 있죠. \n",
    "이를 사용하여 불용어를 제거할 거예요. 이 작업 외에도 모든 영어 문자는 소문자로 만들고, \n",
    "섞여있는 html 태그를 제거하고, 정규 표현식을 통해 각종 특수문자를 제거해서 정말 필요한 내용만 잘 학습할 수 있도록 처리할 거예요.\n",
    "\n",
    "함수의 하단을 보면, NLTK를 이용해 불용어를 제거하는 파트가 있는데, 이는 text 전처리 시에서만 호출하고 \n",
    "이미 상대적으로 문장 길이가 짧은 headlines 전처리할 때는 호출하지 않을 예정이에요. Abstractive한 문장 요약 결과문이 \n",
    "자연스러운 문장이 되려면 이 불용어들이 headlines에는 남아 있는 게 더 좋을 것 같습니다. \n",
    "이 처리를 위해서 함수의 인자로 remove_stopwords를 추가하고, if문을 추가했어요.\n",
    "\n",
    "'''\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text             # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence)   # 괄호로 닫힌 문자열 (...) 제거  Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence)                         # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")])      # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence)                     # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)               # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence)                # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (headlines)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "085eb6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "summary: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 전처리 전, 후의 결과를 확인하기 위해서 임의의 text와 summary를 만들어 함수를 호출해 볼까요.\n",
    "\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62f601e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "결과를 보면 기본적으로 모든 알파벳이 소문자로 변환되고, <br />과 같은 html 태그가 제거되었죠. \n",
    "(or finish)와 같은 괄호로 묶였던 단어 시퀀스가 제거된 것도 확인할 수 있어요. 또한 특수문자가 제거되면서 영어만 남았어요.\n",
    "\n",
    "이제 함수가 잘 작동하는 것을 확인했으니, 훈련 데이터 전체에 대해서 전처리를 수행해볼게요. \n",
    "이때, text의 경우에는 불용어를 제거하고, headlines의 경우에는 불용어를 제거하지 않을 것이므로 \n",
    "따로 호출해서 진행해야 해요. 먼저 Text를 전처리하고, 결과를 확인하기 위해서 상위 5개의 줄을 출력해볼게요.\n",
    "'''\n",
    "\n",
    "# Q. 위의 내용을 참고해서 훈련 데이터 전체의 Text 컬럼의 데이터를 전처리하는 코드를 작성하세요.(반복문 사용)\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리\n",
    "clean_text = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    cleaned_text = preprocess_sentence(row['text'])\n",
    "    clean_text.append(cleaned_text)\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39dbbe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines 전처리 후 결과:  []\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "이제 headlines에 대해서 전처리 함수를 호출해 줄 때는, \n",
    "불용어 제거를 수행하지 않는다는 의미에서 두 번째 인자로 False를 넣어줄게요. <----- 중요\n",
    "\n",
    "Q. 위의 내용을 참고해서 훈련 데이터 전체의 headlines 컬럼의 데이터를 전처리하는 코드를 작성하세요.(반복문 사용)\n",
    "\n",
    "'''\n",
    "\n",
    "# 전체 Headlines 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "\n",
    "\n",
    "clean_headlines = []\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리\n",
    "clean_headlines = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    cleaned_text = preprocess_sentence(row['headlines'], False)\n",
    "    clean_text.append(cleaned_text)\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"headlines 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2ffc862",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (295203) does not match length of index (98360)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/1161445341.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m '''\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headlines'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_headlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3610\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m         \"\"\"\n\u001b[0;32m-> 3784\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m         if (\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4509\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \"\"\"\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (295203) does not match length of index (98360)"
     ]
    }
   ],
   "source": [
    "'''\n",
    "이렇게 텍스트 정제의 과정을 거친 후에는 다시 한번 빈(empty) 샘플이 생겼는지 확인해보는 것이 좋아요. \n",
    "정제 전에는 데이터가 존재했지만, 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있어요. \n",
    "이렇게 되면 샘플 자체가 빈 값을 가지게 되겠죠.\n",
    "\n",
    "보다 쉽게 확인하기 위해 데이터들을 데이터프레임에 재저장할게요. 빈(empty) 값을 가진 샘플들이 있다면, \n",
    "모두 Null 값을 가진 샘플로 대체해요.\n",
    "\n",
    "'''\n",
    "\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac215e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 사항에 대한 수정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a89f06e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <훈련데이터와 테스트데이터 나누기>\n",
    "\n",
    "# 학습을 진행하기 위해서는 학습에 사용할 데이터의 크기를 결정하고, 문장의 시작과 끝을 표시해 줘야 해요.\n",
    "\n",
    "#샘플의 최대 길이 정하기\n",
    "\n",
    "\n",
    "#필요 없는 단어를 모두 솎아낸 데이터를 가지게 되었으니, 이제 훈련에 사용할 샘플의 최대 길이를 정해줄 차례에요.\n",
    "#Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화해서 볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de65ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 91\n",
      "텍스트의 평균 길이 : 58.23813542090281\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 18\n",
      "요약의 평균 길이 : 9.553660024400163\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e25a784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# <참고 필요>    <--- 아래는 상황에 맞게 조정 필요함\n",
    "\n",
    "'''\n",
    "위의 그래프처럼, 많은 양의 데이터를 다룰 때는 데이터를 시각화하여 보는 것이 도움이 돼요. \n",
    "위에서부터 차례대로 그래프는 각각 실제 텍스트와 요약의 길이 분포, 실제 텍스트 샘플 길이별 개수, \n",
    "요약본 샘플 길이별 개수를 나타내고 있어요.\n",
    "\n",
    "Text의 경우 최소 길이가 2, 최대 길이가 1,235로 그 차이가 굉장히 크죠. \n",
    "하지만 평균 길이는 38로 시각화된 그래프로 봤을 때는 대체적으로는 100 내외의 길이를 가진다는 것을 확인할 수 있어요.\n",
    "\n",
    "Summary의 경우 최소 길이가 1, 최대 길이가 28, 그리고 평균 길이가 4로 Text에 비해 상대적으로 길이가 매우 짧아요. \n",
    "그래프로 봤을 때에도 대체적으로 10이하의 길이를 가지고 있네요.\n",
    "\n",
    "이로부터 Text의 최대 길이와 Summary의 적절한 최대 길이를 임의로 정해볼게요.\n",
    "\n",
    "'''\n",
    "\n",
    "text_max_len = 70\n",
    "headlines_max_len = 17\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "735e5264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "      <td>sostoken upGrad learner switches to career in ...</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "      <td>sostoken Delhi techie wins free food from Swig...</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "      <td>sostoken New Zealand end Rohit Sharma-led Indi...</td>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "      <td>sostoken Aegon life iTerm insurance plan helps...</td>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "      <td>sostoken Have known Hirani for yrs, what if Me...</td>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
       "1  Kunal Shah's credit card bill payment platform...   \n",
       "2  New Zealand defeated India by 8 wickets in the...   \n",
       "3  With Aegon Life iTerm Insurance plan, customer...   \n",
       "4  Speaking about the sexual harassment allegatio...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upGrad learner switches to career in ...   \n",
       "1  sostoken Delhi techie wins free food from Swig...   \n",
       "2  sostoken New Zealand end Rohit Sharma-led Indi...   \n",
       "3  sostoken Aegon life iTerm insurance plan helps...   \n",
       "4  sostoken Have known Hirani for yrs, what if Me...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upGrad learner switches to career in ML & Al w...  \n",
       "1  Delhi techie wins free food from Swiggy for on...  \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...  \n",
       "3  Aegon life iTerm insurance plan helps customer...  \n",
       "4  Have known Hirani for yrs, what if MeToo claim...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "시작 토큰과 종료 토큰 추가하기\n",
    "앞서 시작 토큰과 종료 토큰에 대해서 언급했던 것을 기억하시나요? \n",
    "디코더는 시작 토큰을 입력받아 문장을 생성하기 시작하고, 종료 토큰을 예측한 순간에 문장 생성을 멈추는 거였죠.\n",
    "\n",
    "content img\n",
    "\n",
    "[시작 토큰 SOS와 종료 토큰 EOS는 각각 start of a sequence와 end of a sequence를 나타낸다]\n",
    "https://arxiv.org/pdf/1812.02303.pdf\n",
    "seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있어요. \n",
    "이번 실습에서는 시작 토큰은 sostoken, 종료 토큰은 eostoken이라 임의로 명명하고 앞, 뒤로 추가할 거예요. \n",
    "디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 decoder_input, 디코더의 출력 또는 \n",
    "레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장의 이름을 decoder_target이라고 이름을 정했어요. \n",
    "두 개의 문장 모두 Summary 열로부터 만들 거예요.\n",
    "\n",
    "'''\n",
    "\n",
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d101eba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c33ac7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 앞뒤로 토큰이 잘 붙었죠? 인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장해 줄게요.\n",
    "\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "195eb115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20069 42123 92763 ... 83566 91190 56668]\n"
     ]
    }
   ],
   "source": [
    "# <훈련 데이터 및 테스트 데이터 분리>\n",
    "\n",
    "'''\n",
    "이제 훈련 데이터와 테스트 데이터를 분리할거에요.\n",
    "\n",
    "훈련 데이터와 테스트 데이터를 분리하는 방법은 분리 패키지를 사용하는 방법, \n",
    "또는 직접 코딩을 통해서 분리하는 방법 등 여러 가지 방법이 있을 텐데 여기서는 직접 해볼게요. \n",
    "우선, encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들어줄게요.\n",
    "'''\n",
    "\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03a53156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해 주면 잘 섞인 샘플이 되겠죠.\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f21f3559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19672\n"
     ]
    }
   ],
   "source": [
    "# 이제 섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리해 줄게요. \n",
    "# 전체 데이터의 크기에서 0.2를 곱해서 테스트 데이터의 크기를 정의해 줄게요.\n",
    "\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2317d4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78688\n",
      "훈련 레이블의 개수 : 78688\n",
      "테스트 데이터의 개수 : 19672\n",
      "테스트 레이블의 개수 : 19672\n"
     ]
    }
   ],
   "source": [
    "# 이렇게 정의한 테스트 데이터의 개수를 이용해 전체 데이터를 양분할게요. :표시의 위치에 주의해 주세요.\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5d125889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터가 각각 78,688 개와 19,672 개로 잘 분리된 것을 볼 수 있어요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa758cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리하기 (3) 정수 인코딩\n",
    "\n",
    "# 단어 집합(vocabulary) 만들기 및 정수 인코딩\n",
    "\n",
    "'''\n",
    "제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꾸어 주어야 해요. \n",
    "이를 위해서는 각 단어에 고유한 정수를 맵핑하는 작업이 필요해요. 이 과정을 단어 집합(vocabulary) 을 만든다고 표현해요. \n",
    "훈련 데이터에 대해서 단어 집합을 만들어볼게요. 우선, 원문에 해당되는 encoder_input_train에 대해서 단어 집합을 만들게요.\n",
    "\n",
    "Keras의 토크나이저를 사용하면, 입력된 훈련 데이터로부터 단어 집합을 만들 수 있어요.\n",
    "'''\n",
    "\n",
    "src_tokenizer = Tokenizer()                        # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)    # 입력된 데이터로부터 단어 집합 생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55ebfd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 91298\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 66518\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 24780\n",
      "단어 집합에서 희귀 단어의 비율: 72.85811299261759\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.726917427448619\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었어요. \n",
    "현재 생성된 단어 집합은 src_tokenizer.word_index에 저장되어 있어요. \n",
    "그런데 우리는 이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아니라, \n",
    "빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행하려고 해요.\n",
    "\n",
    "등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해볼게요.\n",
    "\n",
    "src_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장돼 있는데, \n",
    "이를 통해서 통계적인 정보를 얻을 수 있어요.\n",
    "\n",
    "'''\n",
    "\n",
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index)      # 단어의 수\n",
    "rare_cnt = 0                                   # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0                                 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0                                  # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "\n",
    "   # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    \n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c9ad5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nencoder_input_train에는 3만여 개의 단어가 있네요. 그 아래의 통계 정보들을 해석해볼까요?\\n\\n등장 빈도가 threshold 값인 7회 미만, 즉 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지하네요. \\n하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.39%밖에 되지 않아요.\\n\\n그래서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 합니다. \\n위에서 이를 제외한 단어 집합의 크기를 8천여 개로 계산했는데, 이와 비슷한 값으로 어림잡아 \\n단어 집합의 크기를 8,000으로 제한해볼게요. 토크나이저를 정의할 때 num_words의 값을 정해주면, \\n단어 집합의 크기를 제한할 수 있어요.\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <참고 필요> --> 아래는 상황에 맞게 추수 조정 필요함.\n",
    "\n",
    "'''\n",
    "encoder_input_train에는 3만여 개의 단어가 있네요. 그 아래의 통계 정보들을 해석해볼까요?\n",
    "\n",
    "등장 빈도가 threshold 값인 7회 미만, 즉 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지하네요. \n",
    "하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.39%밖에 되지 않아요.\n",
    "\n",
    "그래서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 합니다. \n",
    "위에서 이를 제외한 단어 집합의 크기를 8천여 개로 계산했는데, 이와 비슷한 값으로 어림잡아 \n",
    "단어 집합의 크기를 8,000으로 제한해볼게요. 토크나이저를 정의할 때 num_words의 값을 정해주면, \n",
    "단어 집합의 크기를 제한할 수 있어요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5046d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0562de62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntexts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 \\n모두 정수로 변환하는 정수 인코딩을 수행해요. \\n현재 단어 집합의 크기를 8,000으로 제한했으니까 이제 8,000이 넘는 숫자들은 \\n정수 인코딩 후에는 데이터에 존재하지 않아요.\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "texts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 \n",
    "모두 정수로 변환하는 정수 인코딩을 수행해요. \n",
    "현재 단어 집합의 크기를 8,000으로 제한했으니까 이제 8,000이 넘는 숫자들은 \n",
    "정수 인코딩 후에는 데이터에 존재하지 않아요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "760ddd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 103, 18, 1, 605, 302, 3, 130, 16, 1, 379, 851, 91, 874, 1958, 6, 7145, 9, 1527, 5185, 1041, 1813, 4, 173, 641, 2564, 96, 60, 287, 247, 10, 53, 6585, 44, 4875, 19, 771, 19, 1813, 13, 2958, 760, 164, 25, 292, 9, 53, 51, 10, 247, 1813, 53, 801, 15, 2886, 69, 57], [24, 1257, 8, 33, 528, 48, 3, 874, 5998, 36, 17, 1702, 11, 127, 44, 6, 4, 2829, 61, 796, 64, 3, 3443, 7, 506, 1410, 2, 950, 168, 431, 7577, 1702, 327, 66, 14, 112, 2941, 36, 17, 1847, 5, 148, 3546, 1572, 2941, 128, 148, 1572, 3, 36, 506, 1410, 522], [1, 423, 9, 169, 47, 1885, 12, 3338, 15, 1, 263, 254, 58, 2687, 247, 28, 12, 871, 84, 1466, 1, 1885, 12, 319, 18, 1, 1211, 53, 6, 109, 6505, 34, 6, 180, 1, 1885, 12, 286, 2084, 68, 544, 7, 118]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "120ce240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "이제 더 이상 텍스트 데이터가 아니라 정수가 나오고 있어요.\n",
    "\n",
    "Headlines 데이터에 대해서도 동일한 작업을 수행할게요. \n",
    "케라스의 토크나이저를 사용하여 decoder_input_train을 입력으로 전체 단어 집합과 각 단어에 대한 빈도수를 계산해요.\n",
    "\n",
    "'''\n",
    "\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "743a5ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 40741\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 29457\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11284\n",
      "단어 집합에서 희귀 단어의 비율: 72.30308534400235\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.141013516291801\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었어요. \n",
    "이는 tar_tokenizer.word_index에 저장되어 있어요. tar_tokenizer.word_counts.items()에는 단어와 각 단어의 \n",
    "등장 빈도수가 저장돼 있는데, 이를 통해서 통계적인 정보를 얻어서, 등장 빈도수가 6회 미만인 단어들이 \n",
    "이 데이터에서 얼만큼의 비중을 차지하는지 확인해볼게요.\n",
    "'''\n",
    "\n",
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index)           # 단어의 수\n",
    "rare_cnt = 0                                        # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0                                      # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0                                       # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "    \n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "        \n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab9586aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 29, 5, 914, 92, 7, 330, 4, 245], [1, 330, 510, 5, 4, 67, 1310, 487], [1, 206, 32, 18, 337, 5, 94, 46, 1523], [1, 29, 730, 483, 523, 5], [1, 13, 1439, 3, 1311, 349, 17, 573]]\n",
      "target\n",
      "decoder  [[29, 5, 914, 92, 7, 330, 4, 245, 2], [330, 510, 5, 4, 67, 1310, 487, 2], [206, 32, 18, 337, 5, 94, 46, 1523, 2], [29, 730, 483, 523, 5, 2], [13, 1439, 3, 1311, 349, 17, 573, 2]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "등장 빈도가 5회 이하인 단어들은 단어 집합에서 약 72%를 차지하고 있네요. \n",
    "하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 6.15%밖에 되지 않아요. \n",
    "아까 했던 것과 동일하게 이 단어들은 모두 제거할게요. \n",
    "어림잡아 2,000을 단어 집합의 크기로 제한할게요.\n",
    "\n",
    "'''\n",
    "\n",
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3cd05e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 14\n",
      "삭제할 테스트 데이터의 개수 : 6\n",
      "훈련 데이터의 개수 : 78674\n",
      "훈련 레이블의 개수 : 78674\n",
      "테스트 데이터의 개수 : 19666\n",
      "테스트 레이블의 개수 : 19666\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "정상적으로 정수 인코딩 작업이 끝났어요. 현재 decoder_input_train과 decoder_target_train에는 더 이상 숫자 2,000이 \n",
    "넘는 숫자들은 존재하지 않아요. 그런데 다음 작업인 패딩 하기로 넘어가기 전에 한 가지 점검해야 할 것이 있어요.\n",
    "\n",
    "전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 \n",
    "이제 빈(empty) 샘플이 되었을 가능성이 있어요. 이 현상은 길이가 상대적으로 길었던 원문(Text)의 경우에는 \n",
    "문제가 별로 없겠지만, 애초에 평균 길이가 4밖에 되지 않았던 요약문(Summary)의 경우에는 \n",
    "이 현상이 굉장히 두드러졌을 가능성이 높겠죠.\n",
    "\n",
    "요약문에서 길이가 0이 된 샘플들의 인덱스를 받아와볼게요. 여기서 주의할 점은 요약문인 \n",
    "decoder_input에는 sostoken 또는 decoder_target에는 eostoken이 추가된 상태이고, \n",
    "이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플 수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제되지 않아요. \n",
    "그래서 이제 길이가 0이 된 요약문의 실제 길이는 1로 나올 거예요. 길이 0이 된 decoder_input에는 \n",
    "sostoken, decoder_target에는 eostoken만 남아 있을 테니까요.\n",
    "\n",
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에\n",
    "라는 변수에 저장해볼게요. 이 샘플들은 모두 삭제할 거예요.\n",
    "\n",
    "'''\n",
    "\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "494fbecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터 모두 일정량의 샘플들이 제거된 것을 확인할 수 있어요. 이제 거의 다 왔어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b64fc20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 패딩하기\n",
    "\n",
    "'''\n",
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, \n",
    "이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업을 해주어야 해야 해요. \n",
    "아까 정해두었던 최대 길이로 패딩 해 줄 거에요. 최대 길이보다 짧은 데이터들은 뒤의 \n",
    "공간에 숫자 0을 넣어 최대 길이로 길이를 맞춰줄게요.\n",
    "'''\n",
    "\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a72cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 학습에 필요한 데이터 전처리가 모두 끝났어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cbfc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)\n",
    "\n",
    "# 일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요. \n",
    "# 실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "379d4206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# <모델 설계하기>\n",
    "\n",
    "'''\n",
    "이제는 모델을 설계할 시간이에요. 우선 함수형 API를 이용해서 인코더를 설계해 볼게요.\n",
    "\n",
    "Q.인코더 LSTM 1을 참고해서 나머지 인코더의 LSTM 2, LSTM 3의 코드를 완성하세요.\n",
    "'''\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2)\n",
    "\n",
    "# 전체 인코더 모델\n",
    "encoder_states = [state_h1, state_c1, state_h2, state_c2, state_h3, state_c3]\n",
    "encoder_model = Model(encoder_inputs, [encoder_output3] + encoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "da2963d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([InputSpec(shape=(None, 256), ndim=2), InputSpec(shape=(None, 256), ndim=2), InputSpec(shape=(None, 256), ndim=2), InputSpec(shape=(None, 256), ndim=2)]); however `cell.state_size` is [256, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3830951822.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# 초기 상태를 잘라서 넣어주기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# LSTM 2 및 LSTM 3의 state_h 및 state_c만 가져옴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m       \u001b[0;31m# Perform the call with temporarily replaced input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Remove the additional_specs from input spec and keep the rest. It is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       \u001b[0;31m# important to keep since the input spec was populated by build(), and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    977\u001b[0m                                                 input_list)\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m       \u001b[0;31m# initial_state was passed in call, check compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_state_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m       self.state_spec = [\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m_validate_state_spec\u001b[0;34m(cell_state_sizes, init_state_specs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_cell_state_sizes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_state_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m     for cell_state_spec, cell_state_size in zip(flat_state_specs,\n\u001b[1;32m    621\u001b[0m                                                 flat_cell_state_sizes):\n",
      "\u001b[0;31mValueError\u001b[0m: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([InputSpec(shape=(None, 256), ndim=2), InputSpec(shape=(None, 256), ndim=2), InputSpec(shape=(None, 256), ndim=2), InputSpec(shape=(None, 256), ndim=2)]); however `cell.state_size` is [256, 256]"
     ]
    }
   ],
   "source": [
    "'''\n",
    "임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기를 256으로 정의했어요. hidden state는 LSTM에서 얼만큼의 \n",
    "수용력(capacity)를 가질지를 정하는 파라미터에요. 이 파라미터는 LSTM의 용량의 크기나, LSTM에서의 뉴런의 개수라고 이해하면 돼요. \n",
    "다른 신경망과 마찬가지로, 무조건 용량을 많이 준다고 해서 성능이 반드시 올라가는 것은 아니에요.\n",
    "\n",
    "인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였어요. hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면,\n",
    "3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있죠. 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보내줘야겠죠?\n",
    "\n",
    "또한 LSTM은 dropout 뿐 아니라 recurrent dropout까지 사용할 수 있어요. 일반적인 dropout은 레이어의 weight를 랜덤으로 생략하여 \n",
    "모델의 과적합(overfitting)을 해결해주는 방법이에요.\n",
    "\n",
    "반면 recurrent dropout은 dropout을 레이어가 아닌 time step마다 해주는 방식이에요. 즉 time step의 입력을 랜덤으로 생략해 주는 거죠.\n",
    "recurrent dropout은 일반적인 dropout와 같이 regularization을 해주는 효과가 있고, 과적합을 방지할 수 있다고 해요.\n",
    "\n",
    "아래 그림은 일반적인 dropout과, dropout과 recurrent dropout을 동시에 사용한 것을 시각적으로 표현한 것입니다. \n",
    "색이 있는 화살표는 dropout을 나타낸 것이에요. (색이 다른 것은 다른 dropout mask를 사용했다는 표시인데, \n",
    "지금은 그냥 넘어가셔도 됩니다.) \n",
    "코드를 수정해서 LSTM에 dropout과 recurrent dropout을 모두 사용할 수 있습니다. \n",
    "그렇게 되면 오른쪽 그림과 같은 형태가 되겠군요. 참고로 dropout과 recurrent dropout을 모두 사용한 것을\n",
    "Variational Dropout이라고도 해요.\n",
    "\n",
    "content img\n",
    "[dropout(왼쪽)과 dropout + recurrent dropout(오른쪽)]\n",
    "https://arxiv.org/pdf/1512.05287.pdf\n",
    "참고로 recurrent dropout을 사용하면 아래와 같은 경고문이 뜹니다.\n",
    "\n",
    "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. \n",
    "It will use generic GPU kernel as fallback when running on GPU\n",
    "recurrent dropout을 사용할 시 cuDNN을 사용할 수 없어서 recurrent dropout을 사용하지 않을 때보다 학습 시간이 오래 걸립니다.\n",
    "\n",
    "recurrent dropout에 대한 자세한 내용은 아래의 논문을 참고하세요.\n",
    "\n",
    "Recurrent Dropout without Memory Loss\n",
    "이제 디코더를 설계해볼게요!\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "\n",
    "# 초기 상태를 잘라서 넣어주기\n",
    "initial_state = encoder_states[2:]  # LSTM 2 및 LSTM 3의 state_h 및 state_c만 가져옴\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "86a4d0ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/716800652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 디코더의 출력층\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdecoder_softmax_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdecoder_softmax_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_softmax_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 모델 정의\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "디코더의 임베딩 층과 LSTM을 설계하는 것은 인코더와 거의 동일해요. \n",
    "하지만 LSTM의 입력을 정의할 때, initial_state의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어줘야 해요.\n",
    "\n",
    "디코더의 출력층을 설계해볼게요.\n",
    "'''\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "<프로젝트 보고서: 뉴스 기사 요약>\n",
    "\n",
    "\n",
    "1. 개요\n",
    "\n",
    "이 프로젝트는 뉴스 기사 데이터를 활용하여 추상적 요약과 추출적 요약을 수행하는 것을 목표로 합니다. \n",
    "초기 단계에서는 TensorFlow 및 Keras를 사용하여 Seq2Seq 모델을 구축하려 했으나, \n",
    "아직 코드가 완성되지 않아 성공하지 못한 상태입니다.\n",
    "\n",
    "\n",
    "2. 데이터셋 로드 및 전처리\n",
    "\n",
    "뉴스 기사 데이터는 'news_summary_more.csv'에서 가져왔으며, 데이터에는 원문인 'text'와 요약문인 'headlines'이 포함되어 있습니다. \n",
    "전처리는 HTML 태그 제거, 소문자 변환, 불용어 제거 등을 포함한 다양한 단계로 이루어졌습니다.\n",
    "\n",
    "\n",
    "3. 모델 설계\n",
    "\n",
    "아직 모델 설계 부분의 코드가 완성되지 않았습니다. \n",
    "기본적인 Seq2Seq 모델을 사용하고자 하였으며, 어텐션 메커니즘을 도입하여 더 나은 문장 요약을 기대하고 있습니다.\n",
    "\n",
    "4. 성능 평가\n",
    "현재는 모델 학습이 이루어지지 않았으므로 성능 평가 결과는 얻을 수 없었습니다. \n",
    "모델 학습이 완료된 후에는 검증 데이터셋을 활용하여 성능을 평가할 예정입니다.\n",
    "\n",
    "5. 모델 활용\n",
    "모델이 성공적으로 학습되면, 새로운 뉴스 기사에 대한 추상적 요약 및 추출적 요약을 생성할 수 있을 것이라 예상합니다. \n",
    "이를 통해 모델의 활용 가능성을 확인할 것입니다.\n",
    "\n",
    "6. 결론\n",
    "현재는 코드의 완성이 이루어지지 않아 전체적인 프로젝트 결과를 도출할 수 없었습니다. \n",
    "그러나 프로젝트를 통해 뉴스 기사 요약에 대한 이해를 높이고 Seq2Seq 모델의 구현에 대한 경험을 쌓았습니다. \n",
    "향후에는 코드를 수정하여 프로젝트를 완성하고 뉴스 기사 요약을 생성할 수 있도록 노력하겠습니다.\n",
    "\n",
    "\n",
    "7. 아쉬웠던 점\n",
    "\n",
    "프로젝트 진행 중 발생한 산출물 부재 및 코드 미완성의 이유로 성능 평가 및 결과 도출이 어려웠습니다. \n",
    "그러나 이러한 상황은 프로젝트 진행 중 부족한 자원 및 시간 관리 등의 어려움에서 비롯된 것으로 추측됩니다.\n",
    "더불어 프로젝트에서 다루는 Seq2Seq 모델은 복잡한 구조를 가지고 있어 설계 및 학습에 상당한 시간과 노력이 필요한 부분이며\n",
    "향후에는 이러한 어려움을 극복하고 완성도 높은 모델을 구축하기 위해 더욱 효율적인 작업 방식과 명확한 \n",
    "일정 계획을 수립하여 진행하도록 하겠습니다.\n",
    "'''\n",
    "\n",
    "\n",
    "# <조필선 프로젝트 회고록>\n",
    "\n",
    "'''\n",
    "죄송합니다. 노력은 하였지만 프로젝트를 완성하지 못하였습니다.\n",
    "\n",
    "프로젝트 시작과 끝까지 어제 학습 노드의 설명과 예제 코드를 통해서 코드를 작성하고 출력 확인하는 과정으로 진행했습니다.\n",
    "아쉽게도 이번 프로젝트에서는 모델 구현이 미완성되어 아쉬움이 남지만, 데이터 전처리와 모델 설계 과정에서 \n",
    "딥러닝의 기본에 대한 이해가 조금 더 높아진 것 같습니다. \n",
    "\n",
    "코드의 성공 여부와는 별개로, 불용어 처리, 텍스트 정규화, 어텐션 메커니즘 등 다양한 기법을 적용하는 경험을 통해 \n",
    "딥러닝에 대한 실전 스킬이 향상된 것 같은 느낌을 받았습니다.\n",
    "\n",
    "비록 이번 프로젝트는 미완성되었지만, 여러 난관에 도전하고 그것을 극복해 나가는 과정에서 새로운 도전과 학습의 기회를 \n",
    "찾아낸 경험이 소중하다는 것을 깨달았습니다. \n",
    "\n",
    "또한, 프로젝트의 불완전함이 곧 배움의 시작이라는 인식으로 이번 경험이 저에게는 성장의 계기가 될 것입니다.\n",
    "\n",
    "앞으로도 쉽지 않은 과제일지라도, 프로젝트에서 구현한 모델이 작동되도록 끝까지 노력하고 발전시켜 나가겠습니다. \n",
    "이 경험이 더 나은 결과물을 만들기 위한 동기부여가 될 것이며, 지속적인 학습과 개선을 위해 끊임없는 노력을 기울이겠습니다.\n",
    "\n",
    "감사합니다.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
